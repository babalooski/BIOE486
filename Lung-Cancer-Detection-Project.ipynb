{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2448052,"sourceType":"datasetVersion","datasetId":1481536}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikit-image\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential,load_model\nfrom tensorflow.keras.layers import Dense,Activation,Flatten,Dropout,BatchNormalization,Embedding,TimeDistributed\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,ReLU,Concatenate,concatenate\nfrom tensorflow.keras import regularizers,optimizers,losses\nfrom tensorflow.keras.layers import DepthwiseConv2D,Add,ReLU,GlobalAveragePooling2D,GlobalMaxPooling2D,MultiHeadAttention\nfrom tensorflow.keras.layers import ActivityRegularization,AvgPool2D,Conv2DTranspose\nfrom tensorflow.keras.metrics import Accuracy,Precision,Recall,AUC,TruePositives,TrueNegatives,FalseNegatives,FalsePositives,FalseNegatives,SpecificityAtSensitivity,SensitivityAtSpecificity\nfrom tensorflow.keras.utils import plot_model,to_categorical\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.python.keras.utils import np_utils\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nimport skimage.io\nimport skimage.color\nimport skimage.filters\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:16.844515Z","iopub.execute_input":"2025-06-24T01:08:16.844713Z","iopub.status.idle":"2025-06-24T01:08:34.929842Z","shell.execute_reply.started":"2025-06-24T01:08:16.844694Z","shell.execute_reply":"2025-06-24T01:08:34.928998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir('/kaggle/working')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:34.930840Z","iopub.execute_input":"2025-06-24T01:08:34.931420Z","iopub.status.idle":"2025-06-24T01:08:34.938606Z","shell.execute_reply.started":"2025-06-24T01:08:34.931387Z","shell.execute_reply":"2025-06-24T01:08:34.937701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images=[]\ny=[]\nmasks=[]\n\ngr_shape=(128,128,1)\nimg_shape=(128,128,3)\ninput_dir='/kaggle/input/lidcidri/LIDC-IDRI-slices'\nout_dir='/kaggle/working'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:34.940769Z","iopub.execute_input":"2025-06-24T01:08:34.941011Z","iopub.status.idle":"2025-06-24T01:08:34.958938Z","shell.execute_reply.started":"2025-06-24T01:08:34.940988Z","shell.execute_reply":"2025-06-24T01:08:34.958292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(1,5):\n    img=image.load_img(f'/kaggle/input/lidcidri/LIDC-IDRI-slices/LIDC-IDRI-000'+str(i)+'/nodule-0/images/slice-1.png')\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:34.962040Z","iopub.execute_input":"2025-06-24T01:08:34.962452Z","iopub.status.idle":"2025-06-24T01:08:35.738586Z","shell.execute_reply.started":"2025-06-24T01:08:34.962428Z","shell.execute_reply":"2025-06-24T01:08:35.737806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images=[]\ny=[]\nmask0=[]\nmask1=[]\nmask2=[]\nmask3=[]\nbase_path='/kaggle/input/lidcidri/LIDC-IDRI-slices/LIDC-IDRI-0001'\n\nfor nodule in os.listdir(base_path):\n    im='images'\n    msk0='mask-0'\n    msk1='mask-1'\n    msk2='mask-2'\n    msk3='mask-3'\n    arr=[im,msk0,msk1,msk2,msk3]\n\n    for a in arr:\n        pattern=os.path.join(base_path,nodule,a,'*.png')\n        files=glob(pattern)\n        for filename in files:\n            print(filename)\n            img=image.load_img(filename,target_size=img_shape)\n            img=np.asarray(img)\n            if(a==im):\n                images.append(img)\n            elif(a==msk0):\n                mask0.append(img)\n            elif(a==msk1):\n                mask1.append(img)\n            elif(a==msk2):\n                mask2.append(img)\n            elif(a==msk3):\n                mask3.append(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:35.739418Z","iopub.execute_input":"2025-06-24T01:08:35.739719Z","iopub.status.idle":"2025-06-24T01:08:36.012857Z","shell.execute_reply.started":"2025-06-24T01:08:35.739690Z","shell.execute_reply":"2025-06-24T01:08:36.012236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"i=5\nprint(mask0[i].sum())\nprint(mask1[i].sum())\nprint(mask2[i].sum())\nprint(mask3[i].sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:36.013552Z","iopub.execute_input":"2025-06-24T01:08:36.013800Z","iopub.status.idle":"2025-06-24T01:08:36.018707Z","shell.execute_reply.started":"2025-06-24T01:08:36.013781Z","shell.execute_reply":"2025-06-24T01:08:36.018083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(mask0[i])\nplt.show()\n\nplt.imshow(mask1[i])\nplt.show()\n\nplt.imshow(mask2[i])\nplt.show()\n\nplt.imshow(mask3[i])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:36.019563Z","iopub.execute_input":"2025-06-24T01:08:36.019933Z","iopub.status.idle":"2025-06-24T01:08:36.533693Z","shell.execute_reply.started":"2025-06-24T01:08:36.019886Z","shell.execute_reply":"2025-06-24T01:08:36.533026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gr_shape=(128,128,1)\nimg_shape = (128,128,3)\ninput_dir=\"/kaggle/input/lidcidri/LIDC-IDRI-slices\"\nimages=[]\nmasks=[]\ny=[]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:36.536084Z","iopub.execute_input":"2025-06-24T01:08:36.536705Z","iopub.status.idle":"2025-06-24T01:08:36.540092Z","shell.execute_reply.started":"2025-06-24T01:08:36.536677Z","shell.execute_reply":"2025-06-24T01:08:36.539535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Thres = 5000 / 255\nimages = []\ny = []\nmasks = []\ninput_dir = '/kaggle/input/lidcidri/LIDC-IDRI-slices'\n\nfor patient in os.listdir(input_dir):\n    if len(images) > 2000:\n        break\n    for nodule in os.listdir(os.path.join(input_dir, patient)):\n        mask_paths = {\n            'mask-0': [],\n            'mask-1': [],\n            'mask-2': [],\n            'mask-3': []\n        }\n        # Load images\n        for filename in glob(os.path.join(input_dir, patient, nodule, 'images', '*.png')):\n            img = image.load_img(filename, target_size=img_shape)\n            img = np.asarray(img)\n            images.append(img)\n        # Load masks\n        for mask_type in mask_paths.keys():\n            for filename in glob(os.path.join(input_dir, patient, nodule, mask_type, '*.png')):\n                img = image.load_img(filename, target_size=img_shape)\n                img = np.asarray(img)\n                mask_paths[mask_type].append(img)\n        # Process masks\n        for i in range(len(mask_paths['mask-0'])):\n            white_sum = np.array([mask_paths['mask-0'][i].sum(), mask_paths['mask-1'][i].sum(),\n                                  mask_paths['mask-2'][i].sum(), mask_paths['mask-3'][i].sum()])\n            cnt = np.sum(white_sum > Thres)\n            if cnt > 2:\n                y.append(1)\n                max_index = max(range(4), key=white_sum.__getitem__)\n                masks.append(mask_paths[f'mask-{max_index}'][i])\n            else:\n                y.append(0)\n                min_index = min(range(4), key=white_sum.__getitem__)\n                masks.append(mask_paths[f'mask-{min_index}'][i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:08:36.540733Z","iopub.execute_input":"2025-06-24T01:08:36.540896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images=np.array(images)/255\nmasks=np.array(masks)/255\nlabel=np.array(y)\nprint(images.shape)\nprint(masks.shape)\nprint(label.shape)\nimages1=images[:2000]\nmasks1=masks[:2000]\nlabel1=label[:2000]\nprint(images1.shape)\nprint(masks1.shape)\nprint(label1.shape)\nx_train,x_test,y_train,y_test,mask_train,mask_test = train_test_split(images1,label1,masks1,train_size=0.8, random_state=7)\nprint(x_train.shape)\nprint(mask_train.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n# from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n# from tensorflow.keras.losses import BinaryCrossentropy\n\n# classifier = ResNet152V2(\n#             include_top = False,input_shape=img_shape,\n#              weights='imagenet'\n#            )\n# fine_tune_at = 100\n# for layer in classifier.layers[:fine_tune_at]:\n#     layer.trainable = False\n\n\n# Name='ResNet152V2'\n# model2 = Sequential(name=Name)\n# model2.add(classifier)\n# model2.add(Flatten())\n# model2.add(BatchNormalization())\n# model2.add(Dense(128, activation='relu'))\n# model2.add(Dropout(0.25))\n# model2.add(Dense(32, activation='sigmoid'))\n# model2.add(Dropout(0.25))\n# model2.add(Dense(1, activation='sigmoid'))\n\n# print(model2.summary())\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, BatchNormalization, Dense, Dropout\nfrom tensorflow.keras.applications.resnet_v2 import ResNet152V2\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.losses import BinaryCrossentropy\n\n# Replace these with your actual image dimensions:\n# img_height, img_width, img_channels = 224, 224, 3\nimg_shape = x_train.shape[1:]  \n\n# 1) Load ResNet152V2 backbone WITHOUT pre-trained weights\nbackbone = ResNet152V2(\n    include_top=False,\n    input_shape=img_shape,\n    weights=None    # ← don’t attempt to download imagenet weights\n)\n\n# 2) Freeze the first `fine_tune_at` layers\nfine_tune_at = 100\nfor layer in backbone.layers[:fine_tune_at]:\n    layer.trainable = False\n\n# 3) Build your classifier on top\nName='ResNet152V2'\nmodel2 = Sequential(name=Name)\nmodel2.add(backbone)\nmodel2.add(Flatten())\nmodel2.add(BatchNormalization())\nmodel2.add(Dense(128, activation='relu'))\nmodel2.add(Dropout(0.25))\nmodel2.add(Dense(32, activation='sigmoid'))\nmodel2.add(Dropout(0.25))\nmodel2.add(Dense(1, activation='sigmoid'))\n\n# 4) Compile (example)\nmodel2.compile(\n    optimizer='adam',\n    loss=BinaryCrossentropy(),\n    metrics=['accuracy']\n)\n\n# 5) Print summary\nmodel2.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel2.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=['acc', Recall(), Precision(), AUC(), TruePositives(), TrueNegatives(), FalseNegatives(), FalsePositives()]\n)\n\n# Plot the model architecture\nplot_model(model2, to_file=Name+'.png', show_shapes=True, show_layer_names=True)\n\n# Configure callbacks\ncheckpoint_filepath = 'checkpoint.weights.h5'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    save_best_only=True,\n    save_freq=5000\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_acc',\n    patience=15,\n    min_delta=0.001,\n    mode='max',\n    restore_best_weights=True\n)\n\n# Train the model\nhistory = model2.fit(\n    x_train,\n    y_train,\n    validation_data=(x_test, y_test),\n    batch_size=64,\n    epochs=30,\n    callbacks=[model_checkpoint_callback, early_stopping]\n)\n\n# Plot accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower left')\nplt.savefig(Name+'acc.png')\nplt.show()\n\n# Plot loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig(Name+'loss.png')\nplt.show()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\n# ------------------------------------------------------------\n# 1) Predict on the test-set\n# ------------------------------------------------------------\ny_prob = model2.predict(x_test, batch_size=64)          # shape (N, 1)\ny_pred = (y_prob > 0.5).astype(int).ravel()             # → 0 / 1\n\n# ------------------------------------------------------------\n# 2) Confusion-matrix & report\n# ------------------------------------------------------------\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion matrix:\\n\", cm)\n\nprint(\"\\nClassification report:\")\nprint(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n\n# ------------------------------------------------------------\n# 3) Plot\n# ------------------------------------------------------------\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=['Negative', 'Positive'])\nfig, ax = plt.subplots(figsize=(4, 4))\ndisp.plot(cmap='Blues', ax=ax, colorbar=False, values_format='d')\nplt.title('ResNet152V2 – Confusion Matrix')\nplt.tight_layout()\nplt.show()\n\n# Save the model\nmodel2.save(Name+'.h5')\n\n# Save history to CSV\npd.DataFrame.from_dict(history.history).to_csv(Name+'.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower left')\nplt.savefig(Name+'acc.png')\nplt.show()\n\n# Plot loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig(Name+'loss.png')\nplt.show()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\n# ------------------------------------------------------------\n# 1) Predict on the test-set\n# ------------------------------------------------------------\ny_prob = model2.predict(x_test, batch_size=64)          # shape (N, 1)\ny_pred = (y_prob > 0.5).astype(int).ravel()             # → 0 / 1\n\n# ------------------------------------------------------------\n# 2) Confusion-matrix & report\n# ------------------------------------------------------------\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion matrix:\\n\", cm)\n\nprint(\"\\nClassification report:\")\nprint(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n\n# ------------------------------------------------------------\n# 3) Plot\n# ------------------------------------------------------------\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=['Negative', 'Positive'])\nfig, ax = plt.subplots(figsize=(4, 4))\ndisp.plot(cmap='Blues', ax=ax, colorbar=False, values_format='d')\nplt.title('ResNet152V2 – Confusion Matrix')\nplt.tight_layout()\nplt.show()\n\n# Save the model\nmodel2.save(Name+'.h5')\n\n# Save history to CSV\npd.DataFrame.from_dict(history.history).to_csv(Name+'.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, regularizers\n\n\ndef block(inp, filters):\n    L1 = tf.keras.layers.Conv2D(filters, 1, activation='relu', padding='same', kernel_initializer='he_normal')(inp)\n    L2 = tf.keras.layers.BatchNormalization()(L1)\n    L3 = tf.keras.layers.Dropout(0.25)(L2)\n\n    M1 = tf.keras.layers.Conv2D(filters, 1, activation='relu', padding='same', kernel_initializer='he_normal')(inp)\n    M2 = tf.keras.layers.Conv2D(filters * 2, 3, activation='relu', padding=\"same\")(M1)\n    M3 = tf.keras.layers.Conv2D(filters, 3, activation='relu', padding='same')(M2)\n    M4 = tf.keras.layers.BatchNormalization(axis=1)(M3)\n    M5 = tf.keras.layers.Dropout(0.25)(M4)\n\n    N1 = tf.keras.layers.Conv2D(filters, 1, activation='relu', padding=\"same\", kernel_initializer='he_normal')(inp)\n    N2 = tf.keras.layers.Conv2D(filters, 3, activation='relu', padding=\"same\")(inp)\n    N3 = tf.keras.layers.BatchNormalization(axis=1)(N2)\n\n    concat = tf.keras.layers.Concatenate()([L3, M5, N3, inp])\n    O1 = tf.keras.layers.Conv2D(filters * 2, 1, activation='relu', padding='same', kernel_initializer='he_normal')(concat)\n    output = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(O1)\n    return output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Name = \"CNNRegulized\"\ninputs = tf.keras.Input(shape=img_shape, name=Name)\nA1 = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\nA2 = layers.MaxPooling2D(pool_size=(2, 2))(A1)\nA3 = layers.BatchNormalization()(A2)\nA4 = layers.Dropout(0.25)(A3)\n\nB1 = block(A4, 32)\nB2 = block(B1, 64)\nB3 = block(B2, 128)\n\nC1 = layers.Flatten()(B3)\nC2 = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.02))(C1)\nC3 = layers.Dropout(0.25)(C2)\nC4 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.02))(C3)\nC5 = layers.Dropout(0.25)(C4)\noutputs = layers.Dense(1, activation='sigmoid')(C5)\n\nmodel = tf.keras.Model(inputs, outputs, name=Name)\nprint(model.summary())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import losses\nfrom tensorflow.keras.metrics import Recall, Precision, AUC, TruePositives, TrueNegatives, FalseNegatives, FalsePositives\n\nmodel.compile(\n    optimizer='adam',\n    loss=losses.BinaryCrossentropy(),\n    metrics=['acc', Recall(), Precision(), AUC(), TruePositives(), TrueNegatives(), FalseNegatives(), FalsePositives()]\n)\n\nplot_model(\n    model,\n    to_file=Name+'.png',\n    show_shapes=True,\n    show_layer_names=True\n)\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=30,\n    validation_data=(x_test, y_test),\n    batch_size=64,\n)\n\n# Plot Accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower left')\nplt.savefig(Name + '_acc.png')\nplt.show()\n\n# Plot Loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig(Name + '_loss.png')\nplt.show()\n\n# Save Model\nmodel.save(Name + '.h5')\n\n# Save History\npd.DataFrame.from_dict(history.history).to_csv(Name + '.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\n# ------------------------------------------------------------\n# 1) Predict on the test-set\n# ------------------------------------------------------------\ny_prob = model.predict(x_test, batch_size=64)          # shape (N, 1)\ny_pred = (y_prob > 0.5).astype(int).ravel()             # → 0 / 1\n\n# ------------------------------------------------------------\n# 2) Confusion-matrix & report\n# ------------------------------------------------------------\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion matrix:\\n\", cm)\n\nprint(\"\\nClassification report:\")\nprint(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n\n# ------------------------------------------------------------\n# 3) Plot\n# ------------------------------------------------------------\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=['Negative', 'Positive'])\nfig, ax = plt.subplots(figsize=(4, 4))\ndisp.plot(cmap='Blues', ax=ax, colorbar=False, values_format='d')\nplt.title('ResNet152V2 – Confusion Matrix')\nplt.tight_layout()\nplt.show()\n\n# Save the model\nmodel2.save(Name+'.h5')\n\n# Save history to CSV\npd.DataFrame.from_dict(history.history).to_csv(Name+'.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg19 import VGG19\nimg_shape = x_train.shape[1:]  \nclassifier = VGG19(include_top=False, input_shape=img_shape, weights='imagenet')\n\n# Freeze layers up to a certain point\nfine_tune_at = 100\nfor layer in classifier.layers[:fine_tune_at]:\n    layer.trainable = False\n\nName = 'VGG19'\nmodel3 = Sequential()\nmodel3.add(classifier)\nmodel3.add(Flatten())\nmodel3.add(BatchNormalization())\nmodel3.add(Dense(128, activation='relu'))\nmodel3.add(Dropout(0.25))\nmodel3.add(Dense(32, activation='sigmoid'))\nmodel3.add(Dropout(0.25))\nmodel3.add(Dense(1, activation='sigmoid'))\n\nprint(model3.summary())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel3.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=['acc', Recall(), Precision(), AUC(), TruePositives(), TrueNegatives(), FalseNegatives(), FalsePositives()]\n)\n\n# Plot the model architecture\nplot_model(model3, to_file=Name+'.png', show_shapes=True, show_layer_names=True)\n\n# Configure callbacks\ncheckpoint_filepath = 'checkpoint.hdf5'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    save_best_only=True,\n    save_freq=5000\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_acc',\n    patience=15,\n    min_delta=0.001,\n    mode='max',\n    restore_best_weights=True\n)\n\n# Train the model\nhistory = model3.fit(\n    x_train,\n    y_train,\n    epochs=1,\n    validation_data=(x_test, y_test),\n    batch_size=64,\n    callbacks=[model_checkpoint_callback, early_stopping]\n)\n\n# Compile the model\nmodel3.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=['acc', Recall(), Precision(), AUC(), TruePositives(), TrueNegatives(), FalseNegatives(), FalsePositives()]\n)\n\n# Plot the model architecture\nplot_model(model3, to_file=Name+'.png', show_shapes=True, show_layer_names=True)\n\n# Configure callbacks\ncheckpoint_filepath = 'checkpoint.hdf5'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    save_best_only=True,\n    save_freq=5000\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_acc',\n    patience=15,\n    min_delta=0.001,\n    mode='max',\n    restore_best_weights=True\n)\n\n# Train the model\nhistory = model3.fit(\n    x_train,\n    y_train,\n    epochs=1,\n    validation_data=(x_test, y_test),\n    batch_size=64,\n    callbacks=[model_checkpoint_callback, early_stopping]\n)\n\n# Plot accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower left')\nplt.savefig(Name+'acc.png')\nplt.show()\n\n# Plot loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig(Name+'loss.png')\nplt.show()\n\n# Save the model\nmodel3.save(Name+'.h5')\n\n#Save history to CSV\n#p# # Compile the model\nmodel3.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=['acc', Recall(), Precision(), AUC(), TruePositives(), TrueNegatives(), FalseNegatives(), FalsePositives()]\n)\n\n# Plot the model architecture\nplot_model(model3, to_file=Name+'.png', show_shapes=True, show_layer_names=True)\n\n# Configure callbacks\ncheckpoint_filepath = 'checkpoint.hdf5'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    save_best_only=True,\n    save_freq=5000\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_acc',\n    patience=15,\n    min_delta=0.001,\n    mode='max',\n    restore_best_weights=True\n)\n\n# Train the model\nhistory = model3.fit(\n    x_train,\n    y_train,\n    epochs=1,\n    validation_data=(x_test, y_test),\n    batch_size=64,\n    callbacks=[model_checkpoint_callback, early_stopping]\n)\n\n# Plot accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower left')\nplt.savefig(Name+'acc.png')\nplt.show()\n\n# Plot loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig(Name+'loss.png')\nplt.show()\n\n# Save the model\nmodel3.save(Name+'.h5')\n\n# Save history to CSV\npd.DataFrame.from_dict(history.history).to_csv(Name+'.csv', index=False).DataFrame.from_dict(history.history).to_csv(Name+'.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install vit_keras","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\nfrom keras_hub import vit\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Assuming img_shape is defined somewhere in your code\n# img_shape = (height, width, channels)\n\n# Define the ViT model\ndef build_vit(img_shape):\n    vit_model = vit.vit_b16(\n\n        image_size=img_shape[:2],\n        activation='sigmoid',\n        pretrained=True\n    )\n\n    # Build the model\n    model = Sequential(name='Vision_Transformer')\n    model.add(vit_model)\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(32, activation='sigmoid'))\n    model.add(Dropout(0.25))\n    model.add(Dense(1, activation='sigmoid'))\n\n    # Compile the model\n    model.compile(\n        optimizer=Adam(),\n        loss=BinaryCrossentropy(),\n        metrics=['acc', Precision(), Recall(), AUC(), TruePositives(), TrueNegatives(), FalsePositives(), FalseNegatives()]\n    )\n\n    return model\n\n# Build the ViT model\nmodel2 = build_vit(img_shape)\n\n# Print the model summary\nprint(model2.summary())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure callbacks\ncheckpoint_filepath = 'checkpoint.hdf5'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    save_best_only=True,\n    save_freq=5000\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_acc',\n    patience=15,\n    min_delta=0.001,\n    mode='max',\n    restore_best_weights=True\n)\n\n# Train the model\nhistory = model2.fit(\n    x_train,\n    y_train,\n    epochs=30,\n    validation_data=(x_test, y_test),\n    batch_size=64,\n    callbacks=[model_checkpoint_callback, early_stopping]\n)\n\n# Plot accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower left')\nplt.savefig('accuracy.png')\nplt.show()\n\n# Plot loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig('loss.png')\nplt.show()\n\n# Save the model\nmodel2.save('model.h5')\n\n# Save history to CSV\npd.DataFrame.from_dict(history.history).to_csv('history.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower left')\nplt.savefig('accuracy.png')\nplt.show()\n\n# Plot loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig('loss.png')\nplt.show()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\n# ------------------------------------------------------------\n# 1) Predict on the test-set\n# ------------------------------------------------------------\ny_prob = model2.predict(x_test, batch_size=64)          # shape (N, 1)\ny_pred = (y_prob > 0.5).astype(int).ravel()             # → 0 / 1\n\n# ------------------------------------------------------------\n# 2) Confusion-matrix & report\n# ------------------------------------------------------------\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion matrix:\\n\", cm)\n\nprint(\"\\nClassification report:\")\nprint(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n\n# ------------------------------------------------------------\n# 3) Plot\n# ------------------------------------------------------------\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=['Negative', 'Positive'])\nfig, ax = plt.subplots(figsize=(4, 4))\ndisp.plot(cmap='Blues', ax=ax, colorbar=False, values_format='d')\nplt.title('ResNet152V2 – Confusion Matrix')\nplt.tight_layout()\nplt.show()\n\n# Save the model\nmodel2.save(Name+'.h5')\n\n# Save history to CSV\npd.DataFrame.from_dict(history.history).to_csv(Name+'.csv', index=False)\n# Save the model\nmodel2.save('model.h5')\n\n# Save history to CSV\npd.DataFrame.from_dict(history.history).to_csv('history.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}